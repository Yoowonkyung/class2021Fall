{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yoowonkyung/class2021Fall/blob/main/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUO0sYwyGfU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6xZ08xsgO7"
      },
      "source": [
        "import nltk\n",
        "#tokenization = 단어별로 쪼개주는 것"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHEyyNHntcZ"
      },
      "source": [
        "text = 'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently — they’re not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can’t do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5RnISmEIA_Q",
        "outputId": "5adcab55-c668-477c-c202-00180f3b8e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "text[0:10]\n",
        "#왼쪽이 시작, 오른쪽이 끝(빈칸까지 포함, 10은 포함 안됨)\n",
        "text[:10]\n",
        "#왼쪽이 없다면 제일 처음부터 \n",
        "text[0:]\n",
        "#오른쪽이 없다면 제일 끝까지\n",
        "text[:]\n",
        "#전체\n",
        "text[:-1]\n",
        "#-1은 포함 안 하므로 -2까지, 결국 마지막 '.'이 빠짐"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Here’s to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently — they’re not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can’t do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45jV2UYs1GEC"
      },
      "source": [
        "words=text.split()\n",
        "#text내에 split이라는 함수가 포함되어 있음 -> 실행하면 list가 나옴 \n",
        "#' '.join(words)하면 원상태로 다시 다 묶임"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_lPZMHntcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4864c84-fdf4-4249-e6f2-ccfafde69f71"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(text)\n",
        "words\n",
        "#기호는 기호별로, 단어는 단어별로 잘 끊어짐. 이것을 tokenize라고 함 "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " '’',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " ',',\n",
              " 'the',\n",
              " 'misfits',\n",
              " ',',\n",
              " 'the',\n",
              " 'rebels',\n",
              " ',',\n",
              " 'the',\n",
              " 'troublemakers',\n",
              " ',',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes',\n",
              " '.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '—',\n",
              " 'they',\n",
              " '’',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules',\n",
              " '.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " ',',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " ',',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " '’',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things',\n",
              " '.',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " ',',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " ',',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " ',',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc42Plwx56YS"
      },
      "source": [
        "### Normalization  \n",
        "Stemming: am → am, the going → the go, having → hav  \n",
        "Lemmatization: am → be, the going → the going, having → have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFfoAr259Fs",
        "outputId": "6afeb9e2-2612-45e2-dfce-ba3e8b88d278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "[stemmer.stem(w) for w in words]\n",
        "#normalization=변이형들을 normalization해주는 것\n",
        "#stemming: 원형으로 잘라주는 것, lemmatization: 사전에 등재된 원형으로 완전히 바꿔주는 것\n",
        "#stemmer.stem()=함수 \n",
        "#마지막 줄을 통해 전체 stemming처리가 가능함 "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['here',\n",
              " '’',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazi',\n",
              " 'one',\n",
              " ',',\n",
              " 'the',\n",
              " 'misfit',\n",
              " ',',\n",
              " 'the',\n",
              " 'rebel',\n",
              " ',',\n",
              " 'the',\n",
              " 'troublemak',\n",
              " ',',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'squar',\n",
              " 'hole',\n",
              " '.',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'differ',\n",
              " '—',\n",
              " 'they',\n",
              " '’',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rule',\n",
              " '.',\n",
              " 'you',\n",
              " 'can',\n",
              " 'quot',\n",
              " 'them',\n",
              " ',',\n",
              " 'disagre',\n",
              " 'with',\n",
              " 'them',\n",
              " ',',\n",
              " 'glorifi',\n",
              " 'or',\n",
              " 'vilifi',\n",
              " 'them',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'onli',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " '’',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignor',\n",
              " 'them',\n",
              " 'becaus',\n",
              " 'they',\n",
              " 'chang',\n",
              " 'thing',\n",
              " '.',\n",
              " 'they',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " ',',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazi',\n",
              " 'one',\n",
              " ',',\n",
              " 'we',\n",
              " 'see',\n",
              " 'geniu',\n",
              " ',',\n",
              " 'becaus',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazi',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'chang',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'are',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'do',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkbgNiPd8BdL",
        "outputId": "fada98e1-adbf-40fa-eef4-2562a3697994",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['her',\n",
              " '’',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'on',\n",
              " ',',\n",
              " 'the',\n",
              " 'misfit',\n",
              " ',',\n",
              " 'the',\n",
              " 'rebel',\n",
              " ',',\n",
              " 'the',\n",
              " 'troublemak',\n",
              " ',',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'squ',\n",
              " 'hol',\n",
              " '.',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'diff',\n",
              " '—',\n",
              " 'they',\n",
              " '’',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rul',\n",
              " '.',\n",
              " 'you',\n",
              " 'can',\n",
              " 'quot',\n",
              " 'them',\n",
              " ',',\n",
              " 'disagr',\n",
              " 'with',\n",
              " 'them',\n",
              " ',',\n",
              " 'glor',\n",
              " 'or',\n",
              " 'vil',\n",
              " 'them',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'on',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " '’',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ign',\n",
              " 'them',\n",
              " 'becaus',\n",
              " 'they',\n",
              " 'chang',\n",
              " 'thing',\n",
              " '.',\n",
              " 'they',\n",
              " 'push',\n",
              " 'the',\n",
              " 'hum',\n",
              " 'rac',\n",
              " 'forward',\n",
              " ',',\n",
              " 'and',\n",
              " 'whil',\n",
              " 'som',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'on',\n",
              " ',',\n",
              " 'we',\n",
              " 'see',\n",
              " 'geni',\n",
              " ',',\n",
              " 'becaus',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'ar',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'chang',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'ar',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'do',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIh5pYd8f74"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgIzrjm8_1N"
      },
      "source": [
        "### Stopword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdM2FaN8ntcc",
        "outputId": "b8f61db6-aa57-4aa8-9e82-83a546d98d99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords')\n",
        "#stop cosider할 것들을 다운로드\n",
        "print(words)\n",
        "words = [w for w in words if not w in stopwords.words('english')]\n",
        "print(words)\n",
        "#빈번하게 나오는 전치사 등을 stop consider하는 것\n",
        "#마지막에서 두 번째=stopwords에 있지 않은 것만 골라서 list up하라는 뜻"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['Here', '’', 's', 'to', 'the', 'crazy', 'ones', ',', 'the', 'misfits', ',', 'the', 'rebels', ',', 'the', 'troublemakers', ',', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', '.', 'The', 'ones', 'who', 'see', 'things', 'differently', '—', 'they', '’', 're', 'not', 'fond', 'of', 'rules', '.', 'You', 'can', 'quote', 'them', ',', 'disagree', 'with', 'them', ',', 'glorify', 'or', 'vilify', 'them', ',', 'but', 'the', 'only', 'thing', 'you', 'can', '’', 't', 'do', 'is', 'ignore', 'them', 'because', 'they', 'change', 'things', '.', 'They', 'push', 'the', 'human', 'race', 'forward', ',', 'and', 'while', 'some', 'may', 'see', 'them', 'as', 'the', 'crazy', 'ones', ',', 'we', 'see', 'genius', ',', 'because', 'the', 'ones', 'who', 'are', 'crazy', 'enough', 'to', 'think', 'that', 'they', 'can', 'change', 'the', 'world', ',', 'are', 'the', 'ones', 'who', 'do', '.']\n",
            "['Here', '’', 'crazy', 'ones', ',', 'misfits', ',', 'rebels', ',', 'troublemakers', ',', 'round', 'pegs', 'square', 'holes', '.', 'The', 'ones', 'see', 'things', 'differently', '—', '’', 'fond', 'rules', '.', 'You', 'quote', ',', 'disagree', ',', 'glorify', 'vilify', ',', 'thing', '’', 'ignore', 'change', 'things', '.', 'They', 'push', 'human', 'race', 'forward', ',', 'may', 'see', 'crazy', 'ones', ',', 'see', 'genius', ',', 'ones', 'crazy', 'enough', 'think', 'change', 'world', ',', 'ones', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmwXTL0UA5aw"
      },
      "source": [
        "### Collocation, Concordance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fll4ygxNA3OJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3caa590-371d-4d10-b871-11e7a8d5742e"
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('melville-moby_dick.txt')\n",
        "#멜빌의 모비딕이라는 소설 불러오기 \n",
        "words = nltk.word_tokenize(text)\n",
        "words\n",
        "#tokenizer를 써서 개별 리스트의 word로 만듦(스페이스 제외, 중복된 것도 그냥 셈)\n",
        "#collocation=두 단어가 동시에 나오는 것, concordance=예문 찾기 "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[',\n",
              " 'Moby',\n",
              " 'Dick',\n",
              " 'by',\n",
              " 'Herman',\n",
              " 'Melville',\n",
              " '1851',\n",
              " ']',\n",
              " 'ETYMOLOGY',\n",
              " '.',\n",
              " '(',\n",
              " 'Supplied',\n",
              " 'by',\n",
              " 'a',\n",
              " 'Late',\n",
              " 'Consumptive',\n",
              " 'Usher',\n",
              " 'to',\n",
              " 'a',\n",
              " 'Grammar',\n",
              " 'School',\n",
              " ')',\n",
              " 'The',\n",
              " 'pale',\n",
              " 'Usher',\n",
              " '--',\n",
              " 'threadbare',\n",
              " 'in',\n",
              " 'coat',\n",
              " ',',\n",
              " 'heart',\n",
              " ',',\n",
              " 'body',\n",
              " ',',\n",
              " 'and',\n",
              " 'brain',\n",
              " ';',\n",
              " 'I',\n",
              " 'see',\n",
              " 'him',\n",
              " 'now',\n",
              " '.',\n",
              " 'He',\n",
              " 'was',\n",
              " 'ever',\n",
              " 'dusting',\n",
              " 'his',\n",
              " 'old',\n",
              " 'lexicons',\n",
              " 'and',\n",
              " 'grammars',\n",
              " ',',\n",
              " 'with',\n",
              " 'a',\n",
              " 'queer',\n",
              " 'handkerchief',\n",
              " ',',\n",
              " 'mockingly',\n",
              " 'embellished',\n",
              " 'with',\n",
              " 'all',\n",
              " 'the',\n",
              " 'gay',\n",
              " 'flags',\n",
              " 'of',\n",
              " 'all',\n",
              " 'the',\n",
              " 'known',\n",
              " 'nations',\n",
              " 'of',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'He',\n",
              " 'loved',\n",
              " 'to',\n",
              " 'dust',\n",
              " 'his',\n",
              " 'old',\n",
              " 'grammars',\n",
              " ';',\n",
              " 'it',\n",
              " 'somehow',\n",
              " 'mildly',\n",
              " 'reminded',\n",
              " 'him',\n",
              " 'of',\n",
              " 'his',\n",
              " 'mortality',\n",
              " '.',\n",
              " '``',\n",
              " 'While',\n",
              " 'you',\n",
              " 'take',\n",
              " 'in',\n",
              " 'hand',\n",
              " 'to',\n",
              " 'school',\n",
              " 'others',\n",
              " ',',\n",
              " 'and',\n",
              " 'to',\n",
              " 'teach',\n",
              " 'them',\n",
              " 'by',\n",
              " 'what',\n",
              " 'name',\n",
              " 'a',\n",
              " 'whale-fish',\n",
              " 'is',\n",
              " 'to',\n",
              " 'be',\n",
              " 'called',\n",
              " 'in',\n",
              " 'our',\n",
              " 'tongue',\n",
              " 'leaving',\n",
              " 'out',\n",
              " ',',\n",
              " 'through',\n",
              " 'ignorance',\n",
              " ',',\n",
              " 'the',\n",
              " 'letter',\n",
              " 'H',\n",
              " ',',\n",
              " 'which',\n",
              " 'almost',\n",
              " 'alone',\n",
              " 'maketh',\n",
              " 'the',\n",
              " 'signification',\n",
              " 'of',\n",
              " 'the',\n",
              " 'word',\n",
              " ',',\n",
              " 'you',\n",
              " 'deliver',\n",
              " 'that',\n",
              " 'which',\n",
              " 'is',\n",
              " 'not',\n",
              " 'true',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'HACKLUYT',\n",
              " \"''\",\n",
              " 'WHALE',\n",
              " '.',\n",
              " '...',\n",
              " 'Sw.',\n",
              " 'and',\n",
              " 'Dan',\n",
              " '.',\n",
              " 'HVAL',\n",
              " '.',\n",
              " 'This',\n",
              " 'animal',\n",
              " 'is',\n",
              " 'named',\n",
              " 'from',\n",
              " 'roundness',\n",
              " 'or',\n",
              " 'rolling',\n",
              " ';',\n",
              " 'for',\n",
              " 'in',\n",
              " 'Dan',\n",
              " '.',\n",
              " 'HVALT',\n",
              " 'is',\n",
              " 'arched',\n",
              " 'or',\n",
              " 'vaulted',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " \"WEBSTER'S\",\n",
              " 'DICTIONARY',\n",
              " \"''\",\n",
              " 'WHALE',\n",
              " '.',\n",
              " '...',\n",
              " 'It',\n",
              " 'is',\n",
              " 'more',\n",
              " 'immediately',\n",
              " 'from',\n",
              " 'the',\n",
              " 'Dut',\n",
              " '.',\n",
              " 'and',\n",
              " 'Ger',\n",
              " '.',\n",
              " 'WALLEN',\n",
              " ';',\n",
              " 'A.S.',\n",
              " 'WALW-IAN',\n",
              " ',',\n",
              " 'to',\n",
              " 'roll',\n",
              " ',',\n",
              " 'to',\n",
              " 'wallow',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'RICHARDSON',\n",
              " \"'S\",\n",
              " 'DICTIONARY',\n",
              " 'KETOS',\n",
              " ',',\n",
              " 'GREEK',\n",
              " '.',\n",
              " 'CETUS',\n",
              " ',',\n",
              " 'LATIN',\n",
              " '.',\n",
              " 'WHOEL',\n",
              " ',',\n",
              " 'ANGLO-SAXON',\n",
              " '.',\n",
              " 'HVALT',\n",
              " ',',\n",
              " 'DANISH',\n",
              " '.',\n",
              " 'WAL',\n",
              " ',',\n",
              " 'DUTCH',\n",
              " '.',\n",
              " 'HWAL',\n",
              " ',',\n",
              " 'SWEDISH',\n",
              " '.',\n",
              " 'WHALE',\n",
              " ',',\n",
              " 'ICELANDIC',\n",
              " '.',\n",
              " 'WHALE',\n",
              " ',',\n",
              " 'ENGLISH',\n",
              " '.',\n",
              " 'BALEINE',\n",
              " ',',\n",
              " 'FRENCH',\n",
              " '.',\n",
              " 'BALLENA',\n",
              " ',',\n",
              " 'SPANISH',\n",
              " '.',\n",
              " 'PEKEE-NUEE-NUEE',\n",
              " ',',\n",
              " 'FEGEE',\n",
              " '.',\n",
              " 'PEKEE-NUEE-NUEE',\n",
              " ',',\n",
              " 'ERROMANGOAN',\n",
              " '.',\n",
              " 'EXTRACTS',\n",
              " '(',\n",
              " 'Supplied',\n",
              " 'by',\n",
              " 'a',\n",
              " 'Sub-Sub-Librarian',\n",
              " ')',\n",
              " '.',\n",
              " 'It',\n",
              " 'will',\n",
              " 'be',\n",
              " 'seen',\n",
              " 'that',\n",
              " 'this',\n",
              " 'mere',\n",
              " 'painstaking',\n",
              " 'burrower',\n",
              " 'and',\n",
              " 'grub-worm',\n",
              " 'of',\n",
              " 'a',\n",
              " 'poor',\n",
              " 'devil',\n",
              " 'of',\n",
              " 'a',\n",
              " 'Sub-Sub',\n",
              " 'appears',\n",
              " 'to',\n",
              " 'have',\n",
              " 'gone',\n",
              " 'through',\n",
              " 'the',\n",
              " 'long',\n",
              " 'Vaticans',\n",
              " 'and',\n",
              " 'street-stalls',\n",
              " 'of',\n",
              " 'the',\n",
              " 'earth',\n",
              " ',',\n",
              " 'picking',\n",
              " 'up',\n",
              " 'whatever',\n",
              " 'random',\n",
              " 'allusions',\n",
              " 'to',\n",
              " 'whales',\n",
              " 'he',\n",
              " 'could',\n",
              " 'anyways',\n",
              " 'find',\n",
              " 'in',\n",
              " 'any',\n",
              " 'book',\n",
              " 'whatsoever',\n",
              " ',',\n",
              " 'sacred',\n",
              " 'or',\n",
              " 'profane',\n",
              " '.',\n",
              " 'Therefore',\n",
              " 'you',\n",
              " 'must',\n",
              " 'not',\n",
              " ',',\n",
              " 'in',\n",
              " 'every',\n",
              " 'case',\n",
              " 'at',\n",
              " 'least',\n",
              " ',',\n",
              " 'take',\n",
              " 'the',\n",
              " 'higgledy-piggledy',\n",
              " 'whale',\n",
              " 'statements',\n",
              " ',',\n",
              " 'however',\n",
              " 'authentic',\n",
              " ',',\n",
              " 'in',\n",
              " 'these',\n",
              " 'extracts',\n",
              " ',',\n",
              " 'for',\n",
              " 'veritable',\n",
              " 'gospel',\n",
              " 'cetology',\n",
              " '.',\n",
              " 'Far',\n",
              " 'from',\n",
              " 'it',\n",
              " '.',\n",
              " 'As',\n",
              " 'touching',\n",
              " 'the',\n",
              " 'ancient',\n",
              " 'authors',\n",
              " 'generally',\n",
              " ',',\n",
              " 'as',\n",
              " 'well',\n",
              " 'as',\n",
              " 'the',\n",
              " 'poets',\n",
              " 'here',\n",
              " 'appearing',\n",
              " ',',\n",
              " 'these',\n",
              " 'extracts',\n",
              " 'are',\n",
              " 'solely',\n",
              " 'valuable',\n",
              " 'or',\n",
              " 'entertaining',\n",
              " ',',\n",
              " 'as',\n",
              " 'affording',\n",
              " 'a',\n",
              " 'glancing',\n",
              " 'bird',\n",
              " \"'s\",\n",
              " 'eye',\n",
              " 'view',\n",
              " 'of',\n",
              " 'what',\n",
              " 'has',\n",
              " 'been',\n",
              " 'promiscuously',\n",
              " 'said',\n",
              " ',',\n",
              " 'thought',\n",
              " ',',\n",
              " 'fancied',\n",
              " ',',\n",
              " 'and',\n",
              " 'sung',\n",
              " 'of',\n",
              " 'Leviathan',\n",
              " ',',\n",
              " 'by',\n",
              " 'many',\n",
              " 'nations',\n",
              " 'and',\n",
              " 'generations',\n",
              " ',',\n",
              " 'including',\n",
              " 'our',\n",
              " 'own',\n",
              " '.',\n",
              " 'So',\n",
              " 'fare',\n",
              " 'thee',\n",
              " 'well',\n",
              " ',',\n",
              " 'poor',\n",
              " 'devil',\n",
              " 'of',\n",
              " 'a',\n",
              " 'Sub-Sub',\n",
              " ',',\n",
              " 'whose',\n",
              " 'commentator',\n",
              " 'I',\n",
              " 'am',\n",
              " '.',\n",
              " 'Thou',\n",
              " 'belongest',\n",
              " 'to',\n",
              " 'that',\n",
              " 'hopeless',\n",
              " ',',\n",
              " 'sallow',\n",
              " 'tribe',\n",
              " 'which',\n",
              " 'no',\n",
              " 'wine',\n",
              " 'of',\n",
              " 'this',\n",
              " 'world',\n",
              " 'will',\n",
              " 'ever',\n",
              " 'warm',\n",
              " ';',\n",
              " 'and',\n",
              " 'for',\n",
              " 'whom',\n",
              " 'even',\n",
              " 'Pale',\n",
              " 'Sherry',\n",
              " 'would',\n",
              " 'be',\n",
              " 'too',\n",
              " 'rosy-strong',\n",
              " ';',\n",
              " 'but',\n",
              " 'with',\n",
              " 'whom',\n",
              " 'one',\n",
              " 'sometimes',\n",
              " 'loves',\n",
              " 'to',\n",
              " 'sit',\n",
              " ',',\n",
              " 'and',\n",
              " 'feel',\n",
              " 'poor-devilish',\n",
              " ',',\n",
              " 'too',\n",
              " ';',\n",
              " 'and',\n",
              " 'grow',\n",
              " 'convivial',\n",
              " 'upon',\n",
              " 'tears',\n",
              " ';',\n",
              " 'and',\n",
              " 'say',\n",
              " 'to',\n",
              " 'them',\n",
              " 'bluntly',\n",
              " ',',\n",
              " 'with',\n",
              " 'full',\n",
              " 'eyes',\n",
              " 'and',\n",
              " 'empty',\n",
              " 'glasses',\n",
              " ',',\n",
              " 'and',\n",
              " 'in',\n",
              " 'not',\n",
              " 'altogether',\n",
              " 'unpleasant',\n",
              " 'sadness',\n",
              " '--',\n",
              " 'Give',\n",
              " 'it',\n",
              " 'up',\n",
              " ',',\n",
              " 'Sub-Subs',\n",
              " '!',\n",
              " 'For',\n",
              " 'by',\n",
              " 'how',\n",
              " 'much',\n",
              " 'the',\n",
              " 'more',\n",
              " 'pains',\n",
              " 'ye',\n",
              " 'take',\n",
              " 'to',\n",
              " 'please',\n",
              " 'the',\n",
              " 'world',\n",
              " ',',\n",
              " 'by',\n",
              " 'so',\n",
              " 'much',\n",
              " 'the',\n",
              " 'more',\n",
              " 'shall',\n",
              " 'ye',\n",
              " 'for',\n",
              " 'ever',\n",
              " 'go',\n",
              " 'thankless',\n",
              " '!',\n",
              " 'Would',\n",
              " 'that',\n",
              " 'I',\n",
              " 'could',\n",
              " 'clear',\n",
              " 'out',\n",
              " 'Hampton',\n",
              " 'Court',\n",
              " 'and',\n",
              " 'the',\n",
              " 'Tuileries',\n",
              " 'for',\n",
              " 'ye',\n",
              " '!',\n",
              " 'But',\n",
              " 'gulp',\n",
              " 'down',\n",
              " 'your',\n",
              " 'tears',\n",
              " 'and',\n",
              " 'hie',\n",
              " 'aloft',\n",
              " 'to',\n",
              " 'the',\n",
              " 'royal-mast',\n",
              " 'with',\n",
              " 'your',\n",
              " 'hearts',\n",
              " ';',\n",
              " 'for',\n",
              " 'your',\n",
              " 'friends',\n",
              " 'who',\n",
              " 'have',\n",
              " 'gone',\n",
              " 'before',\n",
              " 'are',\n",
              " 'clearing',\n",
              " 'out',\n",
              " 'the',\n",
              " 'seven-storied',\n",
              " 'heavens',\n",
              " ',',\n",
              " 'and',\n",
              " 'making',\n",
              " 'refugees',\n",
              " 'of',\n",
              " 'long-pampered',\n",
              " 'Gabriel',\n",
              " ',',\n",
              " 'Michael',\n",
              " ',',\n",
              " 'and',\n",
              " 'Raphael',\n",
              " ',',\n",
              " 'against',\n",
              " 'your',\n",
              " 'coming',\n",
              " '.',\n",
              " 'Here',\n",
              " 'ye',\n",
              " 'strike',\n",
              " 'but',\n",
              " 'splintered',\n",
              " 'hearts',\n",
              " 'together',\n",
              " '--',\n",
              " 'there',\n",
              " ',',\n",
              " 'ye',\n",
              " 'shall',\n",
              " 'strike',\n",
              " 'unsplinterable',\n",
              " 'glasses',\n",
              " '!',\n",
              " 'EXTRACTS',\n",
              " '.',\n",
              " '``',\n",
              " 'And',\n",
              " 'God',\n",
              " 'created',\n",
              " 'great',\n",
              " 'whales',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'GENESIS',\n",
              " '.',\n",
              " '``',\n",
              " 'Leviathan',\n",
              " 'maketh',\n",
              " 'a',\n",
              " 'path',\n",
              " 'to',\n",
              " 'shine',\n",
              " 'after',\n",
              " 'him',\n",
              " ';',\n",
              " 'One',\n",
              " 'would',\n",
              " 'think',\n",
              " 'the',\n",
              " 'deep',\n",
              " 'to',\n",
              " 'be',\n",
              " 'hoary',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'JOB',\n",
              " '.',\n",
              " '``',\n",
              " 'Now',\n",
              " 'the',\n",
              " 'Lord',\n",
              " 'had',\n",
              " 'prepared',\n",
              " 'a',\n",
              " 'great',\n",
              " 'fish',\n",
              " 'to',\n",
              " 'swallow',\n",
              " 'up',\n",
              " 'Jonah',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'JONAH',\n",
              " '.',\n",
              " '``',\n",
              " 'There',\n",
              " 'go',\n",
              " 'the',\n",
              " 'ships',\n",
              " ';',\n",
              " 'there',\n",
              " 'is',\n",
              " 'that',\n",
              " 'Leviathan',\n",
              " 'whom',\n",
              " 'thou',\n",
              " 'hast',\n",
              " 'made',\n",
              " 'to',\n",
              " 'play',\n",
              " 'therein',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'PSALMS',\n",
              " '.',\n",
              " '``',\n",
              " 'In',\n",
              " 'that',\n",
              " 'day',\n",
              " ',',\n",
              " 'the',\n",
              " 'Lord',\n",
              " 'with',\n",
              " 'his',\n",
              " 'sore',\n",
              " ',',\n",
              " 'and',\n",
              " 'great',\n",
              " ',',\n",
              " 'and',\n",
              " 'strong',\n",
              " 'sword',\n",
              " ',',\n",
              " 'shall',\n",
              " 'punish',\n",
              " 'Leviathan',\n",
              " 'the',\n",
              " 'piercing',\n",
              " 'serpent',\n",
              " ',',\n",
              " 'even',\n",
              " 'Leviathan',\n",
              " 'that',\n",
              " 'crooked',\n",
              " 'serpent',\n",
              " ';',\n",
              " 'and',\n",
              " 'he',\n",
              " 'shall',\n",
              " 'slay',\n",
              " 'the',\n",
              " 'dragon',\n",
              " 'that',\n",
              " 'is',\n",
              " 'in',\n",
              " 'the',\n",
              " 'sea',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'ISAIAH',\n",
              " \"''\",\n",
              " 'And',\n",
              " 'what',\n",
              " 'thing',\n",
              " 'soever',\n",
              " 'besides',\n",
              " 'cometh',\n",
              " 'within',\n",
              " 'the',\n",
              " 'chaos',\n",
              " 'of',\n",
              " 'this',\n",
              " 'monster',\n",
              " \"'s\",\n",
              " 'mouth',\n",
              " ',',\n",
              " 'be',\n",
              " 'it',\n",
              " 'beast',\n",
              " ',',\n",
              " 'boat',\n",
              " ',',\n",
              " 'or',\n",
              " 'stone',\n",
              " ',',\n",
              " 'down',\n",
              " 'it',\n",
              " 'goes',\n",
              " 'all',\n",
              " 'incontinently',\n",
              " 'that',\n",
              " 'foul',\n",
              " 'great',\n",
              " 'swallow',\n",
              " 'of',\n",
              " 'his',\n",
              " ',',\n",
              " 'and',\n",
              " 'perisheth',\n",
              " 'in',\n",
              " 'the',\n",
              " 'bottomless',\n",
              " 'gulf',\n",
              " 'of',\n",
              " 'his',\n",
              " 'paunch',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'HOLLAND',\n",
              " \"'S\",\n",
              " 'PLUTARCH',\n",
              " \"'S\",\n",
              " 'MORALS',\n",
              " '.',\n",
              " '``',\n",
              " 'The',\n",
              " 'Indian',\n",
              " 'Sea',\n",
              " 'breedeth',\n",
              " 'the',\n",
              " 'most',\n",
              " 'and',\n",
              " 'the',\n",
              " 'biggest',\n",
              " 'fishes',\n",
              " 'that',\n",
              " 'are',\n",
              " ':',\n",
              " 'among',\n",
              " 'which',\n",
              " 'the',\n",
              " 'Whales',\n",
              " 'and',\n",
              " 'Whirlpooles',\n",
              " 'called',\n",
              " 'Balaene',\n",
              " ',',\n",
              " 'take',\n",
              " 'up',\n",
              " 'as',\n",
              " 'much',\n",
              " 'in',\n",
              " 'length',\n",
              " 'as',\n",
              " 'four',\n",
              " 'acres',\n",
              " 'or',\n",
              " 'arpens',\n",
              " 'of',\n",
              " 'land',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'HOLLAND',\n",
              " \"'S\",\n",
              " 'PLINY',\n",
              " '.',\n",
              " '``',\n",
              " 'Scarcely',\n",
              " 'had',\n",
              " 'we',\n",
              " 'proceeded',\n",
              " 'two',\n",
              " 'days',\n",
              " 'on',\n",
              " 'the',\n",
              " 'sea',\n",
              " ',',\n",
              " 'when',\n",
              " 'about',\n",
              " 'sunrise',\n",
              " 'a',\n",
              " 'great',\n",
              " 'many',\n",
              " 'Whales',\n",
              " 'and',\n",
              " 'other',\n",
              " 'monsters',\n",
              " 'of',\n",
              " 'the',\n",
              " 'sea',\n",
              " ',',\n",
              " 'appeared',\n",
              " '.',\n",
              " 'Among',\n",
              " 'the',\n",
              " 'former',\n",
              " ',',\n",
              " 'one',\n",
              " 'was',\n",
              " 'of',\n",
              " 'a',\n",
              " 'most',\n",
              " 'monstrous',\n",
              " 'size',\n",
              " '.',\n",
              " '...',\n",
              " 'This',\n",
              " 'came',\n",
              " 'towards',\n",
              " 'us',\n",
              " ',',\n",
              " 'open-mouthed',\n",
              " ',',\n",
              " 'raising',\n",
              " 'the',\n",
              " 'waves',\n",
              " 'on',\n",
              " 'all',\n",
              " 'sides',\n",
              " ',',\n",
              " 'and',\n",
              " 'beating',\n",
              " 'the',\n",
              " 'sea',\n",
              " 'before',\n",
              " 'him',\n",
              " 'into',\n",
              " 'a',\n",
              " 'foam',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'TOOKE',\n",
              " \"'S\",\n",
              " 'LUCIAN',\n",
              " '.',\n",
              " '``',\n",
              " 'THE',\n",
              " 'TRUE',\n",
              " 'HISTORY',\n",
              " '.',\n",
              " \"''\",\n",
              " '``',\n",
              " 'He',\n",
              " 'visited',\n",
              " 'this',\n",
              " 'country',\n",
              " 'also',\n",
              " 'with',\n",
              " 'a',\n",
              " 'view',\n",
              " 'of',\n",
              " 'catching',\n",
              " 'horse-whales',\n",
              " ',',\n",
              " 'which',\n",
              " 'had',\n",
              " 'bones',\n",
              " 'of',\n",
              " 'very',\n",
              " 'great',\n",
              " 'value',\n",
              " 'for',\n",
              " 'their',\n",
              " 'teeth',\n",
              " ',',\n",
              " 'of',\n",
              " 'which',\n",
              " 'he',\n",
              " 'brought',\n",
              " 'some',\n",
              " 'to',\n",
              " 'the',\n",
              " 'king',\n",
              " '.',\n",
              " '...',\n",
              " 'The',\n",
              " 'best',\n",
              " 'whales',\n",
              " 'were',\n",
              " 'catched',\n",
              " 'in',\n",
              " 'his',\n",
              " 'own',\n",
              " 'country',\n",
              " ',',\n",
              " 'of',\n",
              " 'which',\n",
              " 'some',\n",
              " 'were',\n",
              " 'forty-eight',\n",
              " ',',\n",
              " 'some',\n",
              " 'fifty',\n",
              " 'yards',\n",
              " 'long',\n",
              " '.',\n",
              " 'He',\n",
              " 'said',\n",
              " 'that',\n",
              " 'he',\n",
              " 'was',\n",
              " 'one',\n",
              " 'of',\n",
              " 'six',\n",
              " 'who',\n",
              " 'had',\n",
              " 'killed',\n",
              " 'sixty',\n",
              " 'in',\n",
              " 'two',\n",
              " 'days',\n",
              " '.',\n",
              " \"''\",\n",
              " '--',\n",
              " 'OTHER',\n",
              " 'OR',\n",
              " 'OCTHER',\n",
              " \"'S\",\n",
              " 'VERBAL',\n",
              " 'NARRATIVE',\n",
              " 'TAKEN',\n",
              " 'DOWN',\n",
              " 'FROM',\n",
              " 'HIS',\n",
              " 'MOUTH',\n",
              " 'BY',\n",
              " 'KING',\n",
              " 'ALFRED',\n",
              " ',',\n",
              " 'A.D.',\n",
              " '890',\n",
              " '.',\n",
              " '``',\n",
              " 'And',\n",
              " 'whereas',\n",
              " 'all',\n",
              " 'the',\n",
              " 'other',\n",
              " 'things',\n",
              " ',',\n",
              " 'whether',\n",
              " 'beast',\n",
              " 'or',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVXlhIrAtmf",
        "outputId": "e5e93571-e997-4756-d8a8-8e3ff20a772a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.Text(words).collocations()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
            "whale; Right Whale; Captain Peleg; Mr. Starbuck; New Bedford; Cape\n",
            "Horn; 'ye see; cried Ahab; years ago; lower jaw; white whale; Mrs.\n",
            "Hussey; chief mate; never mind; Father Mapple\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq0wiutwA_au",
        "outputId": "49248b0f-24a1-44b3-db04-66389e95e136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.Text(words).concordance('great', 79, 10)\n",
        "#great를 쓰는 예문 찾기 \n",
        "#79는 전체 문장에서의 스페이스 포함 캐릭터의 개수\n",
        "#10개는 총 예문이 10개라는 뜻"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Displaying 10 of 303 matches:\n",
            "sses ! EXTRACTS . `` And God created great whales . '' -- GENESIS . `` Leviatha\n",
            "JOB . `` Now the Lord had prepared a great fish to swallow up Jonah . '' -- JON\n",
            "t day , the Lord with his sore , and great , and strong sword , shall punish Le\n",
            " it goes all incontinently that foul great swallow of his , and perisheth in th\n",
            "ys on the sea , when about sunrise a great many Whales and other monsters of th\n",
            "rse-whales , which had bones of very great value for their teeth , of which he \n",
            ", the sea-gudgeon retires into it in great security , and there sleeps . '' -- \n",
            "ads . '' -- STOWE 'S ANNALS . `` The great Leviathan that maketh the seas to se\n",
            " ISLANDS . `` By art is created that great Leviathan , called a Commonwealth or\n",
            "t they were forced to proceed with a great deal of caution for fear they should\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8TrCE14vGcT"
      },
      "source": [
        "### Frequency distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdY3m6zSBHic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2bd5291-8015-4e0f-f633-e595486b5e6b"
      },
      "source": [
        "nltk.FreqDist(words).most_common(10)\n",
        "#frequency distribution=어떤 단어들이 자주 나오는지 측정(빈도수)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 19204),\n",
              " ('the', 13715),\n",
              " ('.', 7308),\n",
              " ('of', 6513),\n",
              " ('and', 6010),\n",
              " ('a', 4545),\n",
              " ('to', 4515),\n",
              " (';', 4173),\n",
              " ('in', 3908),\n",
              " ('that', 2978)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSOSzIovvKvE"
      },
      "source": [
        "### Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIcAOAvqntce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b40c6e-7528-44ac-b50a-8e5746cf9d62"
      },
      "source": [
        "nltk.download('words')\n",
        "nltk.corpus.words.words('en')[-20:-1]\n",
        "#dictionary=nltk패키지 안에서 이용 가능 \n",
        "#[-20:]=english 사전 끝에서부터 20개까지 \n",
        "#[-20:-1]= 사전 끝에서부터 19개, 마지막 포함X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['zymosis',\n",
              " 'zymosterol',\n",
              " 'zymosthenic',\n",
              " 'zymotechnic',\n",
              " 'zymotechnical',\n",
              " 'zymotechnics',\n",
              " 'zymotechny',\n",
              " 'zymotic',\n",
              " 'zymotically',\n",
              " 'zymotize',\n",
              " 'zymotoxic',\n",
              " 'zymurgy',\n",
              " 'Zyrenian',\n",
              " 'Zyrian',\n",
              " 'Zyryan',\n",
              " 'zythem',\n",
              " 'Zythia',\n",
              " 'zythum',\n",
              " 'Zyzomys']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAy_Ju7ntce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ef31147-3534-4af2-9d25-868b776f20bb"
      },
      "source": [
        "len(nltk.corpus.words.words('en'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235886"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrVGVc0X9j7r"
      },
      "source": [
        "### Regular expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQKgoQFI_cG-"
      },
      "source": [
        "import re\n",
        "#regular expression=원하는 규칙에 따라 text의 결과를 만들어낼 수 있음(정규표현)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U2pS-NL9p38",
        "outputId": "70064811-bff7-4eea-c89e-b7691692c3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "'''       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
        "\n",
        ".\t        Wildcard, matches any character\n",
        "^abc\t    Matches some pattern abc at the start of a string\n",
        "abc$\t    Matches some pattern abc at the end of a string\n",
        "[abc]\t    Matches one of a set of characters\n",
        "[^abc]    Matches anything but a set of characters\n",
        "[A-Z0-9]\tMatches one of a range of characters\n",
        "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
        "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
        "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
        "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
        "{n}\t      Exactly n repeats where n is a non-negative integer\n",
        "{n,}\t    At least n repeats\n",
        "{,n}\t    No more than n repeats\n",
        "{m,n}\t    At least m and no more than n repeats\n",
        "a(b|c)+\t  Parentheses that indicate the scope of the operators\n",
        "(...)     Matches whatever regular expression is inside the parentheses\n",
        "\n",
        "'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\\n\\n.\\t        Wildcard, matches any character\\n^abc\\t    Matches some pattern abc at the start of a string\\nabc$\\t    Matches some pattern abc at the end of a string\\n[abc]\\t    Matches one of a set of characters\\n[^abc]    Matches anything but a set of characters\\n[A-Z0-9]\\tMatches one of a range of characters\\ned|ing|s\\tMatches one of the specified strings (disjunction)\\n*\\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\\n+\\t        One or more of previous item, e.g. a+, [a-z]+\\n?\\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\\n{n}\\t      Exactly n repeats where n is a non-negative integer\\n{n,}\\t    At least n repeats\\n{,n}\\t    No more than n repeats\\n{m,n}\\t    At least m and no more than n repeats\\na(b|c)+\\t  Parentheses that indicate the scope of the operators\\n(...)     Matches whatever regular expression is inside the parentheses\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ3Udzia0EbN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f4f731-3e27-434a-af99-9a954c013b42"
      },
      "source": [
        "word = 'supercalifragilisticexpialidocious'\n",
        "re.search('[aeiou]li', word)\n",
        "#[aeiout]중에서 하나+ㅣi있는 것을 찾으라는 의미 \n",
        "#span(6,9)=6번째 다음부터 9번째까지라는 의미 "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<re.Match object; span=(6, 9), match='ali'>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp3_Dm9Q_tNQ",
        "outputId": "b3392665-25e0-4c58-828e-f798a30f2e5c"
      },
      "source": [
        "engdict = nltk.corpus.words.words('en')\n",
        "\n",
        "result = [w for w in engdict if re.search('ed$', w)]\n",
        "# result = [w for w in engdict if re.search('^..j..t..$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ah]+$', w)][:10]\n",
        "print(result[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1a5mQYj4hwn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e9700f-7473-410c-91ee-6bc9c54458e5"
      },
      "source": [
        "nltk.download('treebank')\n",
        "wsj = nltk.corpus.treebank.words()\n",
        "\n",
        "result = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
        "# result = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
        "\n",
        "result = sorted(set(result))\n",
        "print(result[:10])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvuVJ_W_AMqG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1cc5e3-17a1-4988-a713-837f03afacf6"
      },
      "source": [
        "word = 'supercalifragilisticexpialidocious'\n",
        "\n",
        "result = re.findall('[aeiou]', word)\n",
        "# result = re.findall('[aeiou](..)[aeiou]', word)\n",
        "# result = re.findall('[^aeiou].+[^aeiou]', word) # greedy search\n",
        "# result = re.findall('[^aeiou].+?[^aeiou]', word) # reluctant search\n",
        "\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ8kKm7a6q6q"
      },
      "source": [
        "diphthongs = [diphthongs for w in wsj for diphthongs in re.findall('[aeiou]{2}', w)]\n",
        "print(diphthongs)\n",
        "\n",
        "nltk.FreqDist(diphthongs).most_common(100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIIqwosCRZa"
      },
      "source": [
        "### Extract information (pos tag, named entity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VBiObftCVwH"
      },
      "source": [
        "sent = \"I am Jhon from America and would like to go to Starbucks\"\n",
        "words = nltk.word_tokenize(sent)\n",
        "#pos tag=품사 분류, named entity=카테고리에 분류 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2HuyzFWCe3U"
      },
      "source": [
        "'''\n",
        "POS tag list:\n",
        "\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tadjective\t'big'\n",
        "JJR\tadjective, comparative\t'bigger'\n",
        "JJS\tadjective, superlative\t'biggest'\n",
        "LS\tlist marker\t1)\n",
        "MD\tmodal\tcould, will\n",
        "NN\tnoun, singular 'desk'\n",
        "NNS\tnoun plural\t'desks'\n",
        "NNP\tproper noun, singular\t'Harrison'\n",
        "NNPS\tproper noun, plural\t'Americans'\n",
        "PDT\tpredeterminer\t'all the kids'\n",
        "POS\tpossessive ending\tparent's\n",
        "PRP\tpersonal pronoun\tI, he, she\n",
        "PRP$\tpossessive pronoun\tmy, his, hers\n",
        "RB\tadverb\tvery, silently,\n",
        "RBR\tadverb, comparative\tbetter\n",
        "RBS\tadverb, superlative\tbest\n",
        "RP\tparticle\tgive up\n",
        "TO\tto\tgo 'to' the store.\n",
        "UH\tinterjection\terrrrrrrrm\n",
        "VB\tverb, base form\ttake\n",
        "VBD\tverb, past tense\ttook\n",
        "VBG\tverb, gerund/present participle\ttaking\n",
        "VBN\tverb, past participle\ttaken\n",
        "VBP\tverb, sing. present, non-3d\ttake\n",
        "VBZ\tverb, 3rd person sing. present\ttakes\n",
        "WDT\twh-determiner\twhich\n",
        "WP\twh-pronoun\twho, what\n",
        "WP$\tpossessive wh-pronoun\twhose\n",
        "WRB\twh-abverb\twhere, when\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwKdu36WCewv",
        "outputId": "34f511ee-41c2-4d41-ca27-8c5d53b530ab"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos = nltk.pos_tag(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnjGT1HpClE0",
        "outputId": "d77c2e60-daec-4123-8577-e0128e10239a"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "NE = nltk.ne_chunk(pos)\n",
        "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}